{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.stats import zscore\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\",None)\n",
    "df = pd.read_csv(\"df.csv\")\n",
    "\n",
    "fdf = df.sort_values(by='time_epoch', ascending=True)           # SORT VALUES BY TIME \n",
    "fdf = fdf[fdf[\"Source\"] == 2]                                   # FIXED SOURCE SELECTION\n",
    "fdf[\"time_epoch\"] = fdf[\"time_epoch\"].diff().fillna(0)          # TIME EPOCH DIFFERENCE BETWEEN VALUES CORRESPONDING\n",
    "fdf = fdf[(fdf[\"time_epoch\"] < 1)]                              # DEFINED THRESHOLD\n",
    "\n",
    "fdf = fdf[['time_epoch','RSSI','speed_kmh_source','speed_kmh_destination','distance']]  # LIMIT DATAPOINTS\n",
    "fdf = fdf.head(80_000)\n",
    "fdf.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Data Standardization\n",
    "fdf['RSSI'] = zscore(fdf['RSSI'])\n",
    "\n",
    "#  Min-Max scaling for speed_kmh_source and speed_kmh_destination\n",
    "scaler = MinMaxScaler()\n",
    "fdf[['speed_kmh_source', 'speed_kmh_destination']] = scaler.fit_transform(fdf[['speed_kmh_source', 'speed_kmh_destination']])\n",
    "\n",
    "# Log transformation for time_epoch and re-normalize to [0, 1] (if needed)\n",
    "fdf['time_epoch'] = fdf['time_epoch'].apply(lambda x: np.log1p(x))  # log(1 + x) to handle zero values\n",
    "fdf['time_epoch'] = scaler.fit_transform(fdf[['time_epoch']])       # Min-Max scaling to keep values between [0, 1]\n",
    "fdf['log_distance'] = np.log(fdf['distance'] + 1)\n",
    "fdf.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features and labels\n",
    "X = fdf[['time_epoch', 'RSSI', 'speed_kmh_source', 'speed_kmh_destination']].values  # Features\n",
    "y = fdf['distance'].values  # Target \n",
    "\n",
    "# test train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "# data to tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Data Loader\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "batch_size = 32  \n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # LSTM layer with dropout between layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, \n",
    "                            batch_first=True, dropout=dropout)\n",
    "        \n",
    "        # connected layer\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)  # Get the batch size dynamically\n",
    "        \n",
    "        # hidden & cell states\n",
    "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(x.device)\n",
    "        \n",
    "        # Forward\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        \n",
    "        # dropout in training\n",
    "        out = self.dropout(out[:, -1, :])  \n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# model initialize\n",
    "input_size = 4 \n",
    "hidden_size = 64\n",
    "num_layers = 3\n",
    "output_size = 1  \n",
    "dropout = 0.5  \n",
    "\n",
    "model = LSTMModel(input_size, hidden_size, num_layers, output_size, dropout=dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.MSELoss()  # Mean Squared Error for regression tasks\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam optimizer\n",
    "num_epochs = 10  # Set the number of epochs\n",
    "for epoch in range(num_epochs):\n",
    "    model.train() \n",
    "    for batch_X, batch_y in train_loader:      \n",
    "        optimizer.zero_grad()  # Zero  gradients\n",
    "        outputs = model(batch_X.unsqueeze(1)) # add sequence\n",
    "        loss = criterion(outputs, batch_y.unsqueeze(1))  # loss\n",
    "        loss.backward()  # Backpropagate gradient\n",
    "        optimizer.step()  # Update weights\n",
    "        \n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():  # Disable gradient for evaluation\n",
    "    predictions = []\n",
    "    true_values = []\n",
    "    \n",
    "    for batch_X, batch_y in test_loader:\n",
    "        # Forward pass\n",
    "        outputs = model(batch_X.unsqueeze(1))\n",
    "        predictions.append(outputs.numpy())\n",
    "        true_values.append(batch_y.numpy())\n",
    "\n",
    "    # Convert list to array\n",
    "    predictions = np.concatenate(predictions)\n",
    "    true_values = np.concatenate(true_values)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "mse = mean_squared_error(true_values, predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(true_values, predictions)\n",
    "r2 = r2_score(true_values, predictions)\n",
    "\n",
    "print(f\"MSE: {mse}\")\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"RÂ²: {r2}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
